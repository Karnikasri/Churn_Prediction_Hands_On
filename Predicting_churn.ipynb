{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad1bceda-1400-41ae-a16b-f617f1dd0509",
      "metadata": {
        "id": "ad1bceda-1400-41ae-a16b-f617f1dd0509"
      },
      "source": [
        "# XGBoost Machine Learning Example - Predicting Churn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e3e4259-4870-45cb-afe1-cabc21b6392d",
      "metadata": {
        "id": "0e3e4259-4870-45cb-afe1-cabc21b6392d"
      },
      "source": [
        "## Agenda:\n",
        "0. Problem Formulation\n",
        "1. Loading the Raw Data from Kaggle\n",
        "2. Data Pre-processing\n",
        "3. Running XGBoost\n",
        "4. Hyperparameter Tuning\n",
        "5. Storing Models and Results\n",
        "6. Streamlit App"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce753ee2-6423-40de-8398-42a56d3f068c",
      "metadata": {
        "id": "ce753ee2-6423-40de-8398-42a56d3f068c"
      },
      "source": [
        "## ML Process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0836464-6ef8-413d-815e-e6d5517cba12",
      "metadata": {
        "id": "f0836464-6ef8-413d-815e-e6d5517cba12"
      },
      "source": [
        "# 0. Problem Formulation\n",
        "- Understand which factors influence churn the most\n",
        "- Identify individuals with high probability of churning\n",
        "- Build a churn prediction model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8504ffcc-214f-4a8e-a9bf-d38a6fde6736",
      "metadata": {
        "id": "8504ffcc-214f-4a8e-a9bf-d38a6fde6736"
      },
      "source": [
        "## 1.Loading the Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41fc6570-181a-4c0d-b515-2d6848318226",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "41fc6570-181a-4c0d-b515-2d6848318226",
        "outputId": "ef9bce20-a543-4c5e-c18c-fbcd4709604e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import plotly.express as px\n",
        "!pip install streamlit\n",
        "import streamlit as st\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# pip install xgboost\n",
        "# pip install graphviz\n",
        "\n",
        "# loading excel\n",
        "raw_raw = pd.read_csv(\"Churn_Modelling.csv\", encoding=\"latin1\")\n",
        "# Source: https://www.kaggle.com/datasets/saurabhbadole/bank-customer-churn-prediction-dataset\n",
        "\n",
        "# to see your directory: os.getcwd()\n",
        "# pd.set_option('display.max_rows', None) # display all rows\n",
        "# pd.set_option('display.max_columns', None) # display all columns\n",
        "\n",
        "raw_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6b8fad0-4b80-4aa2-bdfc-1ee00df63ead",
      "metadata": {
        "id": "c6b8fad0-4b80-4aa2-bdfc-1ee00df63ead"
      },
      "source": [
        "## 2. Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4332a62e-b3b1-4e4a-91c1-b11571f049ec",
      "metadata": {
        "id": "4332a62e-b3b1-4e4a-91c1-b11571f049ec"
      },
      "source": [
        "### 2.1. Understanding our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a88491-d7f1-4d88-9a0d-e236d73cc3b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5a88491-d7f1-4d88-9a0d-e236d73cc3b0",
        "outputId": "db36f60a-7ceb-456d-c762-3724ee5f3f01"
      },
      "outputs": [],
      "source": [
        "# Investigate all the elements whithin each Feature\n",
        "\n",
        "for column in raw_raw:\n",
        "    unique_vals = np.unique(raw_raw[column].fillna('0'))\n",
        "    nr_values = len(unique_vals)\n",
        "    if nr_values <= 12:\n",
        "        print('The number of values for feature {} :{} -- {}'.format(column, nr_values,unique_vals))\n",
        "    else:\n",
        "        print('The number of values for feature {} :{}'.format(column, nr_values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812f827d-e3ee-43fc-ae82-c1621cd3b0a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "812f827d-e3ee-43fc-ae82-c1621cd3b0a4",
        "outputId": "e5cfacf8-d2a7-4c75-f9a4-86bc6502d38c"
      },
      "outputs": [],
      "source": [
        "# Checking for null values\n",
        "raw_raw.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4659b18-125e-4031-a2eb-31a920ce240b",
      "metadata": {
        "id": "c4659b18-125e-4031-a2eb-31a920ce240b"
      },
      "source": [
        "### 2.2. Visualizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284bc10b-dedc-42ea-b812-764f01321be5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "284bc10b-dedc-42ea-b812-764f01321be5",
        "outputId": "ec5de61d-f9bd-4aa3-e1ab-55a2b522474e"
      },
      "outputs": [],
      "source": [
        "# Count Plot of our Y - Check the balance of the dataset\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=raw_raw, x=\"Exited\")\n",
        "plt.title(\"Count Plot of Exited\", fontsize=16)\n",
        "plt.xlabel(\"Exited\", fontsize=14)\n",
        "plt.ylabel(\"Count\", fontsize=14)\n",
        "plt.xticks([0, 1], labels=[\"Not Exited\", \"Exited\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e31ce829-93ea-4df7-8eb9-46930817ddf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "e31ce829-93ea-4df7-8eb9-46930817ddf7",
        "outputId": "5464395d-1a52-4388-97ca-ca6c29e09980"
      },
      "outputs": [],
      "source": [
        "# limiting the data\n",
        "raw_raw_v = raw_raw[['CreditScore', 'Geography',\n",
        "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
        "       'IsActiveMember', 'EstimatedSalary', 'Exited']]\n",
        "\n",
        "# Visualizing\n",
        "g = sns.pairplot(raw_raw_v, hue = 'Exited')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a90e23f4-72a7-46b0-93ba-623291d07d70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a90e23f4-72a7-46b0-93ba-623291d07d70",
        "outputId": "cec2690c-2af1-421a-c570-2eaf63e8353f",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Investigate all the features by our y\n",
        "\n",
        "features = ['Geography', 'Gender', 'Age', 'Tenure', 'NumOfProducts', 'HasCrCard',\n",
        "       'IsActiveMember']\n",
        "\n",
        "for f in features:\n",
        "    plt.figure()\n",
        "    ax = sns.countplot(x=f, data=raw_raw_v, hue = 'Exited', palette=\"Set1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2874ea-abf4-42bb-ace2-07d6998dbf72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dd2874ea-abf4-42bb-ace2-07d6998dbf72",
        "outputId": "a6a17370-c745-44d6-c741-6fe146a1a3b9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Investigating the distribution of all Numerical values\n",
        "\n",
        "# identifying all numeric columns\n",
        "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "n_variables = raw_raw_v.select_dtypes(include=numerics).columns\n",
        "\n",
        "# Increases the size of sns plots\n",
        "sns.set(rc={'figure.figsize':(8,5)})\n",
        "\n",
        "for c in n_variables:\n",
        "    x = raw_raw_v[c].values\n",
        "    ax = sns.boxplot(x, color = '#D1EC46')\n",
        "    print('The meadian is: ', raw_raw_v[c].median())\n",
        "    plt.title(c)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b5c3f83-d1d3-4dc5-8a83-9289d17da831",
      "metadata": {
        "id": "5b5c3f83-d1d3-4dc5-8a83-9289d17da831"
      },
      "source": [
        "### 2.3. Preparing the final DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de261fe0-51aa-43ad-ac43-2199340b051d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "de261fe0-51aa-43ad-ac43-2199340b051d",
        "outputId": "c04feed9-926e-43a1-bef5-a443fb5eee10"
      },
      "outputs": [],
      "source": [
        "# Making categorical variables into numeric representation\n",
        "new_raw_data = pd.get_dummies(raw_raw_v, columns = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember'])\n",
        "\n",
        "# Scaling our columns\n",
        "scale_vars = ['CreditScore','EstimatedSalary','Tenure', 'Balance','Age', 'NumOfProducts']\n",
        "scaler = MinMaxScaler()\n",
        "new_raw_data[scale_vars] = scaler.fit_transform(new_raw_data[scale_vars])\n",
        "new_raw_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10c9de1c-ba64-4435-90f6-ccdfaf59b846",
      "metadata": {
        "id": "10c9de1c-ba64-4435-90f6-ccdfaf59b846"
      },
      "source": [
        "# 3. Running XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "693762af-ae50-475b-9350-4a144fe2d417",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "693762af-ae50-475b-9350-4a144fe2d417",
        "outputId": "7a15c050-cbee-4338-8a22-2433c9c485bb"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = new_raw_data.drop(columns=[\"Exited\"])\n",
        "y = new_raw_data[\"Exited\"]\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Training and Testing Accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# Feature Importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    \"Feature\": X_train.columns,\n",
        "    \"Importance\": model.feature_importances_\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "# Plotting feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance[\"Feature\"], feature_importance[\"Importance\"], align=\"center\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
        "plt.show()\n",
        "\n",
        "# Displaying feature importance\n",
        "print(\"\\nFeature Importance:\")\n",
        "feature_importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a37dd2-9532-426b-8ced-f6e6a8f93f20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "16a37dd2-9532-426b-8ced-f6e6a8f93f20",
        "outputId": "26d10f8f-dac1-4e9d-c9a0-c5c52da01ffa"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix function\n",
        "def plot_confusion_matrix(cm, classes=None, title='Confusion Matrix'):\n",
        "    \"\"\"Plots a confusion matrix.\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0, vmax=1, annot=True, cmap=\"Blues\", fmt='.2f')\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred, normalize='true')\n",
        "plot_confusion_matrix(cm, classes=[\"Not Exited\", \"Exited\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c69057ce-92a1-4c66-9b93-8eae4e0a0ffb",
      "metadata": {
        "id": "c69057ce-92a1-4c66-9b93-8eae4e0a0ffb"
      },
      "source": [
        "#### We are not predicting Exited well...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d3da13f-eaef-47e2-b0da-03bc0830e024",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "2d3da13f-eaef-47e2-b0da-03bc0830e024",
        "outputId": "e10cb9bf-07e8-4740-e57d-978e4a1e3b45"
      },
      "outputs": [],
      "source": [
        "# 4. Re-Running XGBoost using SMOTE\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Applying SMOTE to oversample the minority class in the training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = model.predict(X_train_resampled)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Training and Testing Accuracy\n",
        "train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# Plotting Feature Importance\n",
        "feature_importance = model.feature_importances_\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(X_train.columns, feature_importance, align='center')\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b487ba1-c078-4d0c-89f5-b7dea5ebd1bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "9b487ba1-c078-4d0c-89f5-b7dea5ebd1bd",
        "outputId": "f7486915-9e45-414f-c892-6aa7e5650e9d"
      },
      "outputs": [],
      "source": [
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred, normalize='true')\n",
        "plot_confusion_matrix(cm, classes=[\"Not Exited\", \"Exited\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d09b776-204a-43c8-80d1-bf952c5963f9",
      "metadata": {
        "id": "9d09b776-204a-43c8-80d1-bf952c5963f9"
      },
      "source": [
        "##### We can see a slight improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a8b4f92-a9ad-48d1-94e0-d5ce3a4e4411",
      "metadata": {
        "id": "7a8b4f92-a9ad-48d1-94e0-d5ce3a4e4411"
      },
      "source": [
        "### Visualizing the tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f20f973-26d3-4617-b456-2a05c6775553",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "2f20f973-26d3-4617-b456-2a05c6775553",
        "outputId": "257fc3b9-d202-45a6-b0c7-59affd902a53"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import xgboost as xgb\n",
        "\n",
        "# Export the first tree in the ensemble to DOT format\n",
        "dot_data = xgb.to_graphviz(model, num_trees=0)\n",
        "\n",
        "# Save and display the tree\n",
        "output_file = \"xgboost_tree\"\n",
        "dot_data.render(output_file, format=\"png\", view=False)  # Saves 'xgboost_tree.png'\n",
        "\n",
        "# Display the tree image using PIL (for inline visualization in Jupyter or Python)\n",
        "img = Image.open(f\"{output_file}.png\")\n",
        "plt.figure(figsize=(30, 30))\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62fdc71-b267-4097-b8cf-ea2608119cee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "f62fdc71-b267-4097-b8cf-ea2608119cee",
        "outputId": "58289dc0-5596-4790-b9bc-907e000e7915"
      },
      "outputs": [],
      "source": [
        "# Tree visual is not easy to read so we will train a simple DT to visual the tree:\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(random_state=42, max_depth=3)  # Adjust max_depth for simplicity\n",
        "dt.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predictions and evaluation\n",
        "y_train_pred = dt.predict(X_train_resampled)\n",
        "y_test_pred = dt.predict(X_test)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# Export the decision tree to DOT format\n",
        "dot_data = export_graphviz(\n",
        "    dt,\n",
        "    out_file=None,\n",
        "    feature_names=new_raw_data.drop(\"Exited\", axis=1).columns,\n",
        "    class_names=[\"Not Exited\", \"Exited\"],\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    special_characters=True\n",
        ")\n",
        "\n",
        "# Visualize the tree using Graphviz\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49553d8f-9f05-457d-8f60-e48f39155406",
      "metadata": {
        "id": "49553d8f-9f05-457d-8f60-e48f39155406"
      },
      "source": [
        "## 4. Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd033ae-0d39-4eaa-b54f-adb2672d9a18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "7bd033ae-0d39-4eaa-b54f-adb2672d9a18",
        "outputId": "db28a78b-a906-40c8-d8e0-d28d4d58a222"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define the parameter grid for RandomizedSearchCV\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200, 300],  # Number of trees\n",
        "    \"max_depth\": [3, 5, 7, 10],      # Maximum depth of a tree\n",
        "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],  # Step size shrinkage\n",
        "    \"subsample\": [0.6, 0.8, 1.0],    # Fraction of samples to grow trees\n",
        "    \"colsample_bytree\": [0.6, 0.8, 1.0],  # Fraction of features for tree building\n",
        "    \"gamma\": [0, 1, 5],              # Minimum loss reduction for split\n",
        "    \"reg_lambda\": [1, 10, 50],       # L2 regularization term\n",
        "}\n",
        "\n",
        "# Initialize the base XGBoost classifier\n",
        "xgb_base = XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=42)\n",
        "\n",
        "# Apply RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_base,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=50,  # Number of parameter settings sampled\n",
        "    scoring=\"f1\",\n",
        "    cv=3,  # 3-fold cross-validation\n",
        "    random_state=42,\n",
        "    verbose=1,\n",
        "    n_jobs=-1  # Use all available cores\n",
        ")\n",
        "\n",
        "# Fit RandomizedSearchCV\n",
        "random_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Get the best parameters and model\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Re-train the model with the best hyperparameters\n",
        "best_model = random_search.best_estimator_\n",
        "best_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = best_model.predict(X_train_resampled)\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "all_df_predict = best_model.predict(X)\n",
        "all_df_predict_prob = best_model.predict_proba(X)\n",
        "\n",
        "# Training and Testing Accuracy\n",
        "train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# Feature Importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    \"Feature\": X_train.columns,\n",
        "    \"Importance\": best_model.feature_importances_\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "feature_importance\n",
        "# metrics: https://scikit-learn.org/1.5/modules/model_evaluation.html#scoring-parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ce4993-74a4-4bd9-a13a-d49d7bfa3ebd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "05ce4993-74a4-4bd9-a13a-d49d7bfa3ebd",
        "outputId": "11e030f8-f4f4-4bf3-eeda-281d0db270fa"
      },
      "outputs": [],
      "source": [
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred, normalize='true')\n",
        "plot_confusion_matrix(cm, classes=[\"Not Exited\", \"Exited\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53e9c5ac-15d5-4bc3-aef3-1ab23d249827",
      "metadata": {
        "id": "53e9c5ac-15d5-4bc3-aef3-1ab23d249827"
      },
      "source": [
        "## 5. Storing Models and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b45cd2f-0dd1-4c55-abb2-d6982c289a66",
      "metadata": {
        "id": "2b45cd2f-0dd1-4c55-abb2-d6982c289a66"
      },
      "outputs": [],
      "source": [
        "# Adding the predictions back to the original dataset\n",
        "raw_raw['Exited Prediction'] = all_df_predict\n",
        "raw_raw['Exited Prediction Probability'] = all_df_predict_prob[:,1]\n",
        "\n",
        "# Expoprting all the data with predictions\n",
        "raw_raw.to_excel(\"bank_churn_data.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6327a076-76bd-40f9-9c80-14331b59ea49",
      "metadata": {
        "id": "6327a076-76bd-40f9-9c80-14331b59ea49"
      },
      "outputs": [],
      "source": [
        "# Storing the Feature Importances\n",
        "feature_importance['Feature Importance Score'] = feature_importance['Importance'].round(4)\n",
        "feature_importance.to_excel(\"feature_importance.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e2afb0c-b098-4601-9083-6ce979a25e20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2afb0c-b098-4601-9083-6ce979a25e20",
        "outputId": "9f9a28d4-453a-4729-b720-3c037e279b4f"
      },
      "outputs": [],
      "source": [
        "# Save the best_model to a file\n",
        "import pickle\n",
        "\n",
        "with open('best_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_model, file)\n",
        "\n",
        "print(\"Model saved successfully!\")\n",
        "\n",
        "# saving the scaler\n",
        "with open('scaler.pkl', 'wb') as file:\n",
        "    pickle.dump(scaler, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "389d3a61-c265-44da-8571-f5e186913894",
      "metadata": {
        "id": "389d3a61-c265-44da-8571-f5e186913894"
      },
      "source": [
        "## 6. Streamlit App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pPGo3sAPo-dp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPGo3sAPo-dp",
        "outputId": "d06093f8-81b1-4135-e972-b96220fc5c88"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Set Streamlit layout to wide\n",
        "st.set_page_config(layout=\"wide\")\n",
        "\n",
        "# Load the trained model\n",
        "with open('best_model.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "# Load the MinMaxScaler\n",
        "with open('scaler.pkl', 'rb') as file:\n",
        "    scaler = pickle.load(file)\n",
        "\n",
        "# Define the input features for the model\n",
        "feature_names = [\n",
        "    \"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"NumOfProducts\",\n",
        "    \"EstimatedSalary\", \"Geography_France\", \"Geography_Germany\", \"Geography_Spain\",\n",
        "    \"Gender_Female\", \"Gender_Male\", \"HasCrCard_0\", \"HasCrCard_1\",\n",
        "    \"IsActiveMember_0\", \"IsActiveMember_1\"\n",
        "]\n",
        "\n",
        "# Columns requiring scaling\n",
        "scale_vars = [\"CreditScore\", \"EstimatedSalary\", \"Tenure\", \"Balance\", \"Age\", \"NumOfProducts\"]\n",
        "\n",
        "# Updated default values\n",
        "default_values = [\n",
        "    600, 30, 2, 8000, 2, 60000,\n",
        "    True, False, False, True, False, False, True, False, True\n",
        "]\n",
        "\n",
        "# Sidebar setup\n",
        "st.sidebar.image(\"/content/Pic 1.PNG\", use_column_width=True)  # Display Pic 1\n",
        "st.sidebar.header(\"User Inputs\")\n",
        "\n",
        "# Collect user inputs\n",
        "user_inputs = {}\n",
        "for i, feature in enumerate(feature_names):\n",
        "    if feature in scale_vars:\n",
        "        user_inputs[feature] = st.sidebar.number_input(\n",
        "            feature, value=default_values[i], step=1 if isinstance(default_values[i], int) else 0.01\n",
        "        )\n",
        "    elif isinstance(default_values[i], bool):\n",
        "        user_inputs[feature] = st.sidebar.checkbox(feature, value=default_values[i])\n",
        "    else:\n",
        "        user_inputs[feature] = st.sidebar.number_input(\n",
        "            feature, value=default_values[i], step=1\n",
        "        )\n",
        "\n",
        "# Convert inputs to a DataFrame\n",
        "input_data = pd.DataFrame([user_inputs])\n",
        "\n",
        "# Apply MinMaxScaler to the required columns\n",
        "input_data_scaled = input_data.copy()\n",
        "input_data_scaled[scale_vars] = scaler.transform(input_data[scale_vars])\n",
        "\n",
        "# App Header\n",
        "st.image(\"/content/Pic 2.PNG\", use_column_width=True)  # Display Pic 2\n",
        "st.title(\"Customer Churn Prediction\")\n",
        "\n",
        "# Page Layout\n",
        "left_col, right_col = st.columns(2)\n",
        "\n",
        "# Left Page: Feature Importance\n",
        "with left_col:\n",
        "    st.header(\"Feature Importance\")\n",
        "    # Load feature importance data from the Excel file\n",
        "    feature_importance_df = pd.read_excel(\"feature_importance.xlsx\", usecols=[\"Feature\", \"Feature Importance Score\"])\n",
        "    # Plot the feature importance bar chart\n",
        "    fig = px.bar(\n",
        "        feature_importance_df.sort_values(by=\"Feature Importance Score\", ascending=False),\n",
        "        x=\"Feature Importance Score\",\n",
        "        y=\"Feature\",\n",
        "        orientation=\"h\",\n",
        "        title=\"Feature Importance\",\n",
        "        labels={\"Feature Importance Score\": \"Importance\", \"Feature\": \"Features\"},\n",
        "        width=400,  # Set custom width\n",
        "        height=500  # Set custom height\n",
        "    )\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "# Right Page: Prediction\n",
        "with right_col:\n",
        "    st.header(\"Prediction\")\n",
        "    if st.button(\"Predict\"):\n",
        "        # Get the predicted probabilities and label\n",
        "        probabilities = model.predict_proba(input_data_scaled)[0]\n",
        "        prediction = model.predict(input_data_scaled)[0]\n",
        "        # Map prediction to label\n",
        "        prediction_label = \"Churned\" if prediction == 1 else \"Retain\"\n",
        "\n",
        "        # Display results\n",
        "        st.subheader(f\"Predicted Value: {prediction_label}\")\n",
        "        st.write(f\"Predicted Probability: {probabilities[1]:.2%} (Churn)\")\n",
        "        st.write(f\"Predicted Probability: {probabilities[0]:.2%} (Retain)\")\n",
        "        # Display a clear output for the prediction\n",
        "        st.markdown(f\"### Output: **{prediction_label}**\")\n",
        "\n",
        "# Streamlit run churn_pred.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
